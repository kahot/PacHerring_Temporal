{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_dir = 'Users/kahotisthammer/programs/cvtkpy'\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import defaultdict, Counter\n",
    "from itertools import groupby, chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "from matplotlib import cm\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import allel as al"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kahotisthammer/miniconda3/lib/python3.9/site-packages/cvtkpy-0.0.1-py3.9.egg/cvtk/gintervals.py:138: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "/Users/kahotisthammer/miniconda3/lib/python3.9/site-packages/cvtkpy-0.0.1-py3.9.egg/cvtk/gintervals.py:138: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n"
     ]
    }
   ],
   "source": [
    "from cvtk.cvtk import TemporalFreqs, TiledTemporalFreqs\n",
    "from cvtk.cov import stack_temporal_covariances\n",
    "import cvtk.variant_files as vf\n",
    "from cvtk.variant_files import VCFFile\n",
    "from cvtk.gintervals import GenomicIntervals, GenomicInterval\n",
    "from cvtk.pca import FreqPCA\n",
    "from cvtk.plots import rep_plot_pca, correction_diagnostic_plot\n",
    "from cvtk.utils import integerize, integerize_alternate\n",
    "from cvtk.utils import extract_empirical_nulls_diagonals, extract_temporal_cov_diagonals\n",
    "from cvtk.cov import stack_replicate_covariances, stack_temporal_covariances, stack_temporal_covs_by_group, cov_labels\n",
    "from cvtk.cov import temporal_replicate_cov\n",
    "from cvtk.bootstrap import block_bootstrap, cov_estimator, bootstrap_ci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cvtk.G import G_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#%config InlineBackend.figure_format = 'svg'\n",
    "mpl.rcParams['figure.figsize'] = (8.0, 4.0)\n",
    "mpl.rcParams['figure.dpi'] = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in Data\n",
    "\n",
    "Load in the cleaned and combined metadata created in the Herring scripts. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = pd.read_csv('PH_Samples_TempCov.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide into each population\n",
    "md1=md[0:4]\n",
    "md2=md[5:8]\n",
    "md3=md[8:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>pop</th>\n",
       "      <th>year</th>\n",
       "      <th>abbrv_year</th>\n",
       "      <th>sample</th>\n",
       "      <th>real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>PWS</td>\n",
       "      <td>1991</td>\n",
       "      <td>91</td>\n",
       "      <td>PWS91</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>PWS</td>\n",
       "      <td>1996</td>\n",
       "      <td>96</td>\n",
       "      <td>PWS96</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>PWS</td>\n",
       "      <td>2006</td>\n",
       "      <td>6</td>\n",
       "      <td>PWS06</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>PWS</td>\n",
       "      <td>2017</td>\n",
       "      <td>17</td>\n",
       "      <td>PWS17</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   time  pop  year  abbrv_year sample  real\n",
       "0     0  PWS  1991          91  PWS91  True\n",
       "1     1  PWS  1996          96  PWS96  True\n",
       "2     2  PWS  2006           6  PWS06  True\n",
       "3     3  PWS  2017          17  PWS17  True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in VCF file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading file '../Data/vcf/3pops_MD2000_min417_PWS_maf05.vcf.gz'...\n",
      "file '../Data/vcf/3pops_MD2000_min417_PWS_maf05.vcf.gz' loaded.\n",
      "total time to load VCF file: 0.381882115205129 mins.\n"
     ]
    }
   ],
   "source": [
    "#PWS \n",
    "vcf1 = VCFFile('../Data/vcf/3pops_MD2000_min417_PWS_maf05.vcf.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading file '../Data/vcf/3pops_MD2000_min417_SS_maf05.vcf.gz'...\n",
      "file '../Data/vcf/3pops_MD2000_min417_SS_maf05.vcf.gz' loaded.\n",
      "total time to load VCF file: 0.3015035629272461 mins.\n"
     ]
    }
   ],
   "source": [
    "#SS\n",
    "vcf2 = VCFFile('../Data/vcf/3pops_MD2000_min417_SS_maf05.vcf.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading file '../Data/vcf/3pops_MD2000_min417_TB_maf05.vcf.gz'...\n",
      "file '../Data/vcf/3pops_MD2000_min417_TB_maf05.vcf.gz' loaded.\n",
      "total time to load VCF file: 0.4261385679244995 mins.\n"
     ]
    }
   ],
   "source": [
    "#TB\n",
    "vcf3 = VCFFile('../Data/vcf/3pops_MD2000_min417_TB_maf05.vcf.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(351820, 232, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vcf1.geno_mat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group them into each time period "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_sample(x):\n",
    "    \"Parse out the sample metadata from the VCF.\"\n",
    "    ind, pop, year = re.match(r'(?P<ind>[^_]+)_(?P<pop>[A-Z]+)(?P<year>[0-9]+)', x).groups()\n",
    "    sample = pop + year\n",
    "    return (ind, pop, year, sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vcf_pws = pd.DataFrame([parse_sample(str(x)) for x in vcf1.samples],\n",
    "                     columns = ['ind', 'pop', 'year', 'sample'])\n",
    "vcf_ss = pd.DataFrame([parse_sample(str(x)) for x in vcf2.samples],\n",
    "                     columns = ['ind', 'pop', 'year', 'sample'])\n",
    "vcf_tb = pd.DataFrame([parse_sample(str(x)) for x in vcf3.samples],\n",
    "                     columns = ['ind', 'pop', 'year', 'sample'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "subpops1 = defaultdict(list)\n",
    "for i, sample in enumerate(vcf_pws['sample']):\n",
    "    subpops1[sample].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "subpops2 = defaultdict(list)\n",
    "for i, sample in enumerate(vcf_ss['sample']):\n",
    "    subpops2[sample].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "subpops3 = defaultdict(list)\n",
    "for i, sample in enumerate(vcf_tb['sample']):\n",
    "    subpops3[sample].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kahotisthammer/miniconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3444: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "counts_mat1 = vcf1.count_alleles_subpops(subpops1)\n",
    "counts_mat2 = vcf2.count_alleles_subpops(subpops2)\n",
    "counts_mat3 = vcf3.count_alleles_subpops(subpops3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_mat_all1 = vcf1.calc_freqs()\n",
    "freq_mat_all2 = vcf2.calc_freqs()\n",
    "freq_mat_all3 = vcf3.calc_freqs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "depths_mat_all1 = vcf1.N.astype('f')\n",
    "depths_mat_all2 = vcf2.N.astype('f')\n",
    "depths_mat_all3 = vcf3.N.astype('f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndiploids1 = {k:len(subpops1[k]) for k in vcf1.subpops}\n",
    "ndiploids2 = {k:len(subpops2[k]) for k in vcf2.subpops}\n",
    "ndiploids3 = {k:len(subpops3[k]) for k in vcf3.subpops}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndiploids1 = {k:len(subpops1[k]) for k in vcf1.subpops}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PWS17': 56, 'PWS91': 58, 'PWS96': 72, 'PWS06': 46}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndiploids1['PWS06'] = ndiploids1['PWS07']\n",
    "del ndiploids1['PWS07']\n",
    "ndiploids1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "subpops_lkup1 = {sp:i for i, sp in enumerate(vcf1.subpops)}\n",
    "subpops_lkup2 = {sp:i for i, sp in enumerate(vcf2.subpops)}\n",
    "subpops_lkup3 = {sp:i for i, sp in enumerate(vcf3.subpops)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PWS17': 1, 'PWS91': 2, 'PWS96': 3, 'PWS06': 0}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subpops_lkup1['PWS06'] = subpops_lkup1['PWS07']\n",
    "del subpops_lkup1['PWS07']\n",
    "subpops_lkup1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "351820"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No of loci is same for all\n",
    "nloci= freq_mat_all1.shape[1]\n",
    "nloci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#order by years based on 'md' file\n",
    "\n",
    "#1. PWS\n",
    "pws_freqs = []\n",
    "pws_depths = []\n",
    "pws_samples = []\n",
    "pws_ndiploids = []\n",
    "\n",
    "for row in md1.itertuples():\n",
    "    sample = row.sample\n",
    "    freqs = freq_mat_all1[subpops_lkup1[sample], :]\n",
    "    depths = depths_mat_all1[subpops_lkup1[sample], :]        \n",
    "    ndips = ndiploids1[sample]\n",
    "    pws_freqs.append(freqs)\n",
    "    pws_depths.append(depths)\n",
    "    pws_samples.append((row.pop, row.year))\n",
    "    pws_ndiploids.append(ndips)\n",
    "    \n",
    "pws_full_depths_mat = np.row_stack(pws_depths)\n",
    "pws_freq_mat = np.row_stack(pws_freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. SS\n",
    "ss_freqs = []\n",
    "ss_depths = []\n",
    "ss_samples = []\n",
    "ss_ndiploids = []\n",
    "\n",
    "for row in md2.itertuples():\n",
    "    sample = row.sample\n",
    "    if not row.real:\n",
    "        print(sample + \" is a NA sample\")\n",
    "        freqs = np.empty((nloci))\n",
    "        freqs[:] = np.nan\n",
    "        depths = np.empty((nloci))\n",
    "        depths[:] = np.nan\n",
    "        ndips = 0   \n",
    "    else:\n",
    "        freqs = freq_mat_all2[subpops_lkup2[sample], :]\n",
    "        depths = depths_mat_all2[subpops_lkup2[sample], :]        \n",
    "        ndips = ndiploids2[sample]\n",
    "    ss_freqs.append(freqs)\n",
    "    ss_depths.append(depths)\n",
    "    ss_samples.append((row.pop, row.year))\n",
    "    ss_ndiploids.append(ndips)\n",
    "    \n",
    "ss_full_depths_mat = np.row_stack(ss_depths)\n",
    "ss_freq_mat = np.row_stack(ss_freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. TB\n",
    "tb_freqs = []\n",
    "tb_depths = []\n",
    "tb_samples = []\n",
    "tb_ndiploids = []\n",
    "\n",
    "for row in md3.itertuples():\n",
    "    sample = row.sample\n",
    "    if not row.real:\n",
    "        print(sample + \" is a NA sample\")\n",
    "        freqs = np.empty((nloci))\n",
    "        freqs[:] = np.nan\n",
    "        depths = np.empty((nloci))\n",
    "        depths[:] = np.nan\n",
    "        ndips = 0   \n",
    "    else:\n",
    "        freqs = freq_mat_all3[subpops_lkup3[sample], :]\n",
    "        depths = depths_mat_all3[subpops_lkup3[sample], :]        \n",
    "        ndips = ndiploids3[sample]\n",
    "    tb_freqs.append(freqs)\n",
    "    tb_depths.append(depths)\n",
    "    tb_samples.append((row.pop, row.year))\n",
    "    tb_ndiploids.append(ndips)\n",
    "    \n",
    "tb_full_depths_mat = np.row_stack(tb_depths)\n",
    "tb_freq_mat = np.row_stack(tb_freqs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Temporal Freqs Object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to build the tiled `TemporalFreqs` object. We load in the sequence lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "sl_d = pd.read_csv('../data/vcf/chr_sizes.bed', delimiter='\\t', names=['chrom', 'start', 'end'], header=None)\n",
    "\n",
    "seqlens = dict(zip(sl_d['chrom'].values, sl_d['end'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#100,000 interval \n",
    "tile_width = int(1e5)\n",
    "tiles = GenomicIntervals.from_tiles(seqlens, width=tile_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "gi = vcf1.build_gintervals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('PWS', 1991), 58),\n",
       " (('PWS', 1996), 72),\n",
       " (('PWS', 2006), 46),\n",
       " (('PWS', 2017), 56)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the samples\n",
    "list(zip(pws_samples, pws_ndiploids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the frequncy objects with 100,000 tile size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "pws_d = TiledTemporalFreqs(tiles, freqs=pws_freq_mat, depths=pws_full_depths_mat, diploids=pws_ndiploids, gintervals=gi, samples=pws_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_d = TiledTemporalFreqs(tiles, freqs=ss_freq_mat, depths=ss_full_depths_mat, diploids=ss_ndiploids, gintervals=gi, samples=ss_samples)\n",
    "tb_d = TiledTemporalFreqs(tiles, freqs=tb_freq_mat, depths=tb_full_depths_mat, diploids=tb_ndiploids, gintervals=gi, samples=tb_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the genome-wide covariance for each population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gw_covs1 = pws_d.calc_cov() \n",
    "gw_covs2 = ss_d.calc_cov() \n",
    "gw_covs3 = tb_d.calc_cov() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00030385,  0.00072014, -0.00103058],\n",
       "       [ 0.00072014,  0.00011922, -0.00090018],\n",
       "       [-0.00103058, -0.00090018,  0.00231046]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack_temporal_covariances(gw_covs1, pws_d.R, pws_d.T).T[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00327437, -0.00323847],\n",
       "       [-0.00323847,  0.00302079]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SS has only 1 covariance here\n",
    "stack_temporal_covariances(gw_covs2, ss_d.R, ss_d.T).T[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00287723, -0.00043366, -0.00032577],\n",
       "       [-0.00043366,  0.00324222, -0.00197734],\n",
       "       [-0.00032577, -0.00197734,  0.00320491]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack_temporal_covariances(gw_covs3, tb_d.R, tb_d.T).T[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[['var(PWS: 1996-1991)', 'cov(PWS: 1996-1991, PWS: 2006-1996)',\n",
       "         'cov(PWS: 1996-1991, PWS: 2017-2006)'],\n",
       "        ['cov(PWS: 2006-1996, PWS: 1996-1991)', 'var(PWS: 2006-1996)',\n",
       "         'cov(PWS: 2006-1996, PWS: 2017-2006)'],\n",
       "        ['cov(PWS: 2017-2006, PWS: 1996-1991)',\n",
       "         'cov(PWS: 2017-2006, PWS: 2006-1996)', 'var(PWS: 2017-2006)']]],\n",
       "      dtype='<U35')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create labels for plots, for temporal covariances\n",
    "stacked_temp_labs_pws = stack_temporal_covariances(cov_labels(pws_d.R, pws_d.T, pws_d.samples, lab_var=True), pws_d.R, pws_d.T)\n",
    "stacked_temp_labs_pws.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrapping Temporal Covs to obtain 95% CIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kahotisthammer/miniconda3/lib/python3.9/site-packages/cvtkpy-0.0.1-py3.9.egg/cvtk/cov.py:316: RuntimeWarning: Mean of empty slice\n",
      "/Users/kahotisthammer/miniconda3/lib/python3.9/site-packages/numpy/lib/function_base.py:495: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/Users/kahotisthammer/miniconda3/lib/python3.9/site-packages/numpy/core/_methods.py:181: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = um.true_divide(\n",
      "/Users/kahotisthammer/miniconda3/lib/python3.9/site-packages/cvtkpy-0.0.1-py3.9.egg/cvtk/cov.py:348: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "/Users/kahotisthammer/miniconda3/lib/python3.9/site-packages/numpy/lib/function_base.py:2680: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "/Users/kahotisthammer/miniconda3/lib/python3.9/site-packages/numpy/lib/function_base.py:2680: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n",
      "/Users/kahotisthammer/miniconda3/lib/python3.9/site-packages/cvtkpy-0.0.1-py3.9.egg/cvtk/cov.py:375: RuntimeWarning: Mean of empty slice\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbeaa24fe8304dd0ad2b90f874d4bb1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "bootstraps:   0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This calcuates the 'pivot' based confidence intervals (and they are off)\n",
    "gw_covs_cis = pws_d.bootstrap_cov(B=5000, progress_bar=True, average_replicates=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the function to return the 'straps' to manually calculate CIs\n",
    "def bootstrap_cov2(d, B, alpha=0.05, keep_seqids=None, progress_bar=False,\n",
    "                      average_replicates=True, return_straps=False, ci_method='pivot',\n",
    "                      use_bs_estimate=False,\n",
    "                      **kwargs):\n",
    "        \"\"\"\n",
    "        Bootstrap whole covaraince matrix.\n",
    "        Params:\n",
    "           - B: number of bootstraps\n",
    "           - alpha: α level\n",
    "           - keep_seqids: which seqids to include in bootstrap; if None, all are used.\n",
    "           - return_straps: whether to return the actual bootstrap vectors.\n",
    "           - ci_method: 'pivot' or 'percentile'\n",
    "           - **kwargs: passed to calc_cov() and calc_cov_by_tile()\n",
    "\n",
    "        \"\"\"\n",
    "        # our statistic:\n",
    "        cov = d.calc_cov(keep_seqids=keep_seqids, **kwargs)\n",
    "        if average_replicates:\n",
    "            cov = np.nanmean(stack_temporal_covariances(cov, d.R, d.T), axis=2)\n",
    "        # the filter of seqids is done at this step\n",
    "        covs, het_denoms = d.calc_cov_by_tile(return_ratio_parts=True,\n",
    "                                                 keep_seqids=keep_seqids, **kwargs)\n",
    "        covs, het_denoms = np.stack(covs), np.stack(het_denoms)\n",
    "        if use_bs_estimate:\n",
    "            cov = None\n",
    "        return block_bootstrap_ratio_averages2(covs, het_denoms,\n",
    "                                              block_indices=d.tile_indices,\n",
    "                                              estimator=cov_estimator,\n",
    "                                              ci_method=ci_method,\n",
    "                                              statistic=cov,\n",
    "                                              B=B, alpha=alpha,\n",
    "                                              progress_bar=progress_bar,\n",
    "                                              return_straps=return_straps,\n",
    "                                              # kwargs passed directly to cov_estimator\n",
    "                                              average_replicates=average_replicates,\n",
    "                                              R=d.R, T=d.T)\n",
    "                                              \n",
    "                                                                                            \n",
    "                                              \n",
    "                                              \n",
    "def block_bootstrap_ratio_averages2(blocks_numerator, blocks_denominator,\n",
    "                                   block_indices, B, estimator=np.divide,\n",
    "                                   statistic=None,\n",
    "                                   alpha=0.05, return_straps=False,\n",
    "                                   ci_method='pivot', progress_bar=False, **kwargs):\n",
    "    \"\"\"\n",
    "    This block bootstrap is used often for quantities we need to calculate that are\n",
    "    ratios of expectations, e.g. standardized temporal covariance (cov(Δp_t, Δp_s) / p_t(1-p_t))\n",
    "    and G, both of which are expectations over loci. We use the linearity of expectation\n",
    "    to greatly speed up the block bootstrap procedure.\n",
    "\n",
    "    We do so by pre-calculating the expected numerator and denominator for each block,\n",
    "    and then take a weighted average over the bootstrap sample for each the numerator and\n",
    "    denominator, and then take the final ratio.\n",
    "\n",
    "    It's assumed that blocks_numerator and blocks_denominator are both multidimension arrays\n",
    "    with the first dimension being the block (e.g. tile) dimension.\n",
    "    \"\"\"\n",
    "    That = statistic   # for clarity: read T-hat\n",
    "    if progress_bar:\n",
    "        B_range = tnrange(int(B), desc=\"bootstraps\")\n",
    "    else:\n",
    "        B_range = range(int(B))\n",
    "\n",
    "    assert(len(blocks_numerator) == len(blocks_denominator))\n",
    "    blocks = np.arange(len(blocks_numerator), dtype='uint32')\n",
    "\n",
    "    # Calculate the weights\n",
    "    weights = np.array([len(x) for x in block_indices])\n",
    "\n",
    "    # number of samples in resample\n",
    "    nblocks = len(blocks)\n",
    "    straps = list()\n",
    "\n",
    "    for b in B_range:\n",
    "        bidx = np.random.choice(blocks, size=nblocks, replace=True)\n",
    "        exp_numerator = weighted_mean(blocks_numerator[bidx, ...], weights=weights[bidx])\n",
    "        exp_denominator = weighted_mean(blocks_denominator[bidx, ...], weights=weights[bidx])\n",
    "        stat = estimator(exp_numerator, exp_denominator, **kwargs)\n",
    "        straps.append(stat)\n",
    "    straps = np.stack(straps)\n",
    "    if That is None:\n",
    "        That = np.mean(straps, axis=0)\n",
    "    if return_straps:\n",
    "        return That, straps, weights\n",
    "    return That, straps\n",
    "\n",
    "def weighted_mean(array, weights, axis=0):\n",
    "    \"\"\"\n",
    "    Weighted mean for a block of resampled temporal covariance matrices.\n",
    "    This uses masked_array since nothing in numpy can handle ignoring nans and\n",
    "    weighted averages.\n",
    "    \"\"\"\n",
    "    # mask the covariance matrix, since ma.average is the only nanmean\n",
    "    # in numpy that takes weights\n",
    "    array_masked = np.ma.masked_invalid(array)\n",
    "    return np.ma.average(array_masked, axis=axis, weights=weights).data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. PWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "that, straps, weights = bootstrap_cov2(d=pws_d, B=5000, return_straps=True, average_replicates=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00015284, 0.00011545, 0.00011832],\n",
       "       [0.00011545, 0.0001668 , 0.00014805],\n",
       "       [0.00011832, 0.00014805, 0.00018018]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CI = Z*SD(straps)\n",
    "sd=np.std(straps, axis=0)\n",
    "sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.959963984540054"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import norm\n",
    "alpha=0.05\n",
    "z = norm.ppf(1-alpha/2)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "ci=z*sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"PWS_CIs_100kwindow.csv\", ci, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. SS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kahotisthammer/miniconda3/lib/python3.9/site-packages/cvtkpy-0.0.1-py3.9.egg/cvtk/cov.py:316: RuntimeWarning: Mean of empty slice\n",
      "/Users/kahotisthammer/miniconda3/lib/python3.9/site-packages/numpy/lib/function_base.py:495: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/Users/kahotisthammer/miniconda3/lib/python3.9/site-packages/numpy/core/_methods.py:181: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = um.true_divide(\n",
      "/Users/kahotisthammer/miniconda3/lib/python3.9/site-packages/cvtkpy-0.0.1-py3.9.egg/cvtk/cov.py:348: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "/Users/kahotisthammer/miniconda3/lib/python3.9/site-packages/numpy/lib/function_base.py:2680: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "/Users/kahotisthammer/miniconda3/lib/python3.9/site-packages/numpy/lib/function_base.py:2680: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n",
      "/Users/kahotisthammer/miniconda3/lib/python3.9/site-packages/cvtkpy-0.0.1-py3.9.egg/cvtk/cov.py:375: RuntimeWarning: Mean of empty slice\n"
     ]
    }
   ],
   "source": [
    "that, straps2, weights = bootstrap_cov2(d=ss_d, B=5000, return_straps=True, average_replicates=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 2, 2)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "straps2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00018779, 0.00015982],\n",
       "       [0.00015982, 0.00021167]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sd=np.std(straps2, axis=0)\n",
    "sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd=np.std(straps2, axis=0)\n",
    "ci=z*sd\n",
    "np.savetxt(\"SS_CIs_100kwindow.csv\", ci, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. TB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "that, straps3, weights = bootstrap_cov2(d=tb_d, B=5000, return_straps=True, average_replicates=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd=np.std(straps3, axis=0)\n",
    "ci=z*sd\n",
    "np.savetxt(\"TB_CIs_100kwindow.csv\", ci, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
